AssembleModel(
  (backbone): VisionTransformer(
    (patch_embed): ViTEmbeddings(
      (patch_emb): Conv2d(3, 192, kernel_size=(17, 17), stride=(16, 16), padding=(8, 8))
      (pos_embed): SinusoidalPositionalEncoding()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): ViTEncoder(
      (blocks): ModuleList(
        (0): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): ViTBlock(
          (layernorm_before): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (layernorm_after): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (token_mixer): MultiHeadSelfAttention(
            (query): Linear(in_features=192, out_features=192, bias=True)
            (key): Linear(in_features=192, out_features=192, bias=True)
            (value): Linear(in_features=192, out_features=192, bias=True)
            (linear): Linear(in_features=192, out_features=192, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (channel_mlp): ViTChannelMLP(
            (ffn): ModuleList(
              (0): LinearLayer()
              (1): SiLU()
              (2): LinearLayer()
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
  )
  (head): FC(
    (classifier): Linear(in_features=192, out_features=3, bias=True)
  )
)
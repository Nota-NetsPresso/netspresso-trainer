model:
  task: segmentation
  name: segformer
  checkpoint: ./weights/segformer/segformer.pth
  fx_model_checkpoint: ~
  resume_optimizer_checkpoint: ~
  freeze_backbone: False
  architecture:
    full: ~ # auto
    backbone:
      name: segformer
      params:
        intermediate_ratio: 4
        hidden_activation_type: "gelu"
        hidden_dropout_prob: 0.0
        attention_dropout_prob: 0.0
        layer_norm_eps: 1e-5
      stage_params:
        -
          num_blocks: 2
          sr_ratios: 8
          hidden_sizes: 32
          embedding_patch_sizes: 7
          embedding_strides: 4
          num_attention_heads: 1
        -
          num_blocks: 2
          sr_ratios: 4
          hidden_sizes: 64
          embedding_patch_sizes: 3
          embedding_strides: 2
          num_attention_heads: 2
        -
          num_blocks: 2
          sr_ratios: 2
          hidden_sizes: 160
          embedding_patch_sizes: 3
          embedding_strides: 2
          num_attention_heads: 5
        -
          num_blocks: 2
          sr_ratios: 1
          hidden_sizes: 256
          embedding_patch_sizes: 3
          embedding_strides: 2
          num_attention_heads: 8
    head:
      name: all_mlp_decoder
      params:
        decoder_hidden_size: 256
        classifier_dropout_prob: 0.
  losses:
    - criterion: cross_entropy
      weight: ~
      ignore_index: 255
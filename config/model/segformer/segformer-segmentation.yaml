model:
  task: segmentation
  name: segformer
  checkpoint: ./weights/segformer/segformer.safetensors
  fx_model_checkpoint: ~
  resume_optimizer_checkpoint: ~
  freeze_backbone: False
  architecture:
    full: ~ # auto
    backbone:
      name: mixtransformer
      params:
        ffn_intermediate_ratio: 4
        ffn_activation_type: "gelu"
        ffn_dropout_prob: 0.0
        attention_dropout_prob: 0.0
      stage_params:
        -
          num_blocks: 2
          sr_ratios: 8
          encoder_chananels: 32
          embedding_patch_sizes: 7
          embedding_strides: 4
          num_attention_heads: 1
        -
          num_blocks: 2
          sr_ratios: 4
          encoder_chananels: 64
          embedding_patch_sizes: 3
          embedding_strides: 2
          num_attention_heads: 2
        -
          num_blocks: 2
          sr_ratios: 2
          encoder_chananels: 160
          embedding_patch_sizes: 3
          embedding_strides: 2
          num_attention_heads: 5
        -
          num_blocks: 2
          sr_ratios: 1
          encoder_chananels: 256
          embedding_patch_sizes: 3
          embedding_strides: 2
          num_attention_heads: 8
    head:
      name: all_mlp_decoder
      params:
        decoder_hidden_size: 256
        classifier_dropout_prob: 0.
  losses:
    - criterion: cross_entropy
      weight: ~
      ignore_index: 255
model:
  task: segmentation
  name: segformer_b0
  checkpoint:
    use_pretrained: True
    load_head: False
    path: ~
    fx_model_path: ~
    optimizer_path: ~
  freeze_backbone: False
  architecture:
    full: ~ # auto
    backbone:
      name: mixtransformer
      params:
        ffn_intermediate_expansion_ratio: 4
        ffn_act_type: "gelu"
        ffn_dropout_prob: 0.0
        attention_dropout_prob: 0.0
      stage_params:
        -
          num_blocks: 2
          sequence_reduction_ratio: 8
          attention_chananels: 32
          embedding_patch_sizes: 7
          embedding_strides: 4
          num_attention_heads: 1
        -
          num_blocks: 2
          sequence_reduction_ratio: 4
          attention_chananels: 64
          embedding_patch_sizes: 3
          embedding_strides: 2
          num_attention_heads: 2
        -
          num_blocks: 2
          sequence_reduction_ratio: 2
          attention_chananels: 160
          embedding_patch_sizes: 3
          embedding_strides: 2
          num_attention_heads: 5
        -
          num_blocks: 2
          sequence_reduction_ratio: 1
          attention_chananels: 256
          embedding_patch_sizes: 3
          embedding_strides: 2
          num_attention_heads: 8
    head:
      name: all_mlp_decoder
      params:
        intermediate_channels: 256
        classifier_dropout_prob: 0.
        resize_output: [512, 512]
  postprocessor: ~
  losses:
    - criterion: seg_cross_entropy
      weight: ~
      ignore_index: 255 # Default undefined class is 255
model:
  task: classification
  name: efficientformer_l1
  checkpoint:
    use_pretrained: True
    load_head: False
    path: ~
    fx_model_path: ~
    optimizer_path: ~
  freeze_backbone: False
  architecture:
    full: ~ # auto
    backbone:
      name: efficientformer
      params:
        num_attention_heads: 8
        attention_channels: 256  # attention_hidden_size_splitted * num_attention_heads
        attention_dropout_prob: 0.
        attention_value_expansion_ratio: 4
        ffn_intermediate_ratio: 4
        ffn_dropout_prob: 0.
        ffn_act_type: 'gelu'
        vit_num: 1
      stage_params:
        - 
          num_blocks: 3
          channels: 48
        - 
          num_blocks: 2
          channels: 96
        - 
          num_blocks: 6
          channels: 224
        - 
          num_blocks: 4
          channels: 448
    head:
      name: fc
      params:
        num_layers: 1
        intermediate_channels: ~
        act_type: ~
        dropout_prob: 0.
  postprocessor: ~
  losses:
    - criterion: cross_entropy
      label_smoothing: 0.1
      weight: ~
model:
  task: classification
  name: efficientformer_l1
  checkpoint: ./weights/efficientformer/efficientformer_l1_1000d.safetensors
  fx_model_checkpoint: ~
  resume_optimizer_checkpoint: ~
  freeze_backbone: False
  architecture:
    full: ~ # auto
    backbone:
      name: efficientformer
      params:
        num_attention_heads: 8
        attention_channels: 256  # attention_hidden_size_splitted * num_attention_heads
        attention_dropout_prob: 0.
        attention_value_expansion_ratio: 4
        ffn_intermediate_ratio: 4
        ffn_hidden_dropout_prob: 0.
        ffn_act_type: 'gelu'
        vit_num: 1
      stage_params:
        - 
          num_blocks: 3
          hidden_sizes: 48
        - 
          num_blocks: 2
          hidden_sizes: 96
        - 
          num_blocks: 6
          hidden_sizes: 224
        - 
          num_blocks: 4
          hidden_sizes: 448
    head:
      name: fc
      params:
        hidden_size: 1024
        num_layers: 1
  losses:
    - criterion: cross_entropy
      label_smoothing: 0.1
      weight: ~
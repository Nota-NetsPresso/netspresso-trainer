model:
  task: classification
  name: vit_tiny
  checkpoint: ./weights/vit/vit-tiny.pth
  fx_model_checkpoint: ~
  resume_optimizer_checkpoint: ~
  freeze_backbone: False
  architecture:
    full: ~ # auto
    backbone:
      name: vit
      params:
        patch_size: 16
        hidden_size: 192
        num_blocks: 12
        num_attention_heads: 3
        attention_dropout_prob: 0.0
        intermediate_size: 768  # hidden_size * 4
        hidden_dropout_prob: 0.1
        layer_norm_eps: 1e-6
        use_cls_token: True
        vocab_size: 1000
      stage_params: ~
    head:
      name: fc
  losses:
    - criterion: cross_entropy
      label_smoothing: 0.1
      weight: ~
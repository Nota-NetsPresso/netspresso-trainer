version: "3.9"

# docker compose run --service-ports --name trainer-allinone-dev modelsearch-trainer-allinone bash

services:
  modelsearch-trainer-allinone:
    build:
      context: .
      dockerfile: Dockerfile
    image: modelsearch-trainer-allinone:${TAG}
    container_name: modelsearch-trainer-allinone
    ipc: host
    ports:
      # HOST_PORT for tensorboard
      - "50001:50001"
    volumes:
      # from path: your working directory
      - /PATH/TO/modelsearch-trainer-allinone:/workspace
      # from path: your dataset directory
      - /PATH/TO/DATA:/DATA
      # from path: your checkpoint directory
      - /PATH/TO/CHECKPOINT:/CHECKPOINT 
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0', '1', '2', '3' ] # your GPU id(s)
              capabilities: [ gpu ]

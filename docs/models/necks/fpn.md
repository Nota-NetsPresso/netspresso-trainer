# FPN

FPN based on [Feature Pyramid Networks for Object Detection](https://openaccess.thecvf.com/content_cvpr_2017/papers/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.pdf)

The Feature Pyramid Network (FPN) is designed to enhance feature maps given from the backbone, typically used for detection models. Therefore, we also recommend to use it in detection task as well. FPN can create more pyramid deeply than the input feature pyramid from backbone, and in such cases, additional convolution or pooling layers are added.

## Field list

| Field <img width=200/> | Description |
|---|---|
| `name` | (str) Name must be "fpn" to use `FPN` neck. |
| `params.num_outs` | (int) The number of output feature maps. This must greater than or equal to the number of input feature maps. If `end_level` is not the last feature map produced by the backbone, extra levels that generated by setting `num_outs` beyond the number of input feature maps are not allowed. |
| `params.start_level` | (int) Determines the starting index from the list of feature maps produced by the backbone. It defines the number of input feature maps with `end_level`. |
| `params.end_level` | (int) Determines the end index from the list of feature maps produced by the backbone.  If -1, it equals to using up to the last feature map. it defines the number of input feature maps with `start_level`. |
| `params.add_extra_convs` | (str) Defines additional convolution layers for pyramid construction when `num_outs` is greater than the number of input feature maps. Options are `on_input`, `on_lateral`, `on_output`. If `None`, max pooling is applied. |
| `params.relu_before_extra_convs` | (bool) Determines whether to apply the `relu` activation function to the extra convolutions that are generated. |

## Model configuration examples

<details>
  <summary>FPN (4-stage -> 4-stage)</summary>
  
  ```yaml
  model:
    architecture:
      neck:
        name: fpn
        params:
          num_outs: 4
          start_level: 0
          end_level: -1
          add_extra_convs: False
          relu_before_extra_convs: False
  ```
</details>

## Related links
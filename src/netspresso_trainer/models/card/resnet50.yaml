pretrained:
  original_link: https://download.pytorch.org/models/resnet50-0676ba61.pth
  state_dict_key: ~
example_input: [1, 3, 256, 256]
mapping:
  conv1.weight: conv1.block.conv.weight
  bn1.running_mean: conv1.block.norm.running_mean
  bn1.running_var: conv1.block.norm.running_var
  bn1.weight: conv1.block.norm.weight
  bn1.bias: conv1.block.norm.bias
  layer1.0.conv1.weight: layer1.0.conv1.block.conv.weight
  layer1.0.bn1.weight: layer1.0.conv1.block.norm.weight
  layer1.0.bn1.bias: layer1.0.conv1.block.norm.bias
  layer1.0.bn1.running_mean: layer1.0.conv1.block.norm.running_mean
  layer1.0.bn1.running_var: layer1.0.conv1.block.norm.running_var
  layer1.0.conv2.weight: layer1.0.conv2.block.conv.weight
  layer1.0.bn2.weight: layer1.0.conv2.block.norm.weight
  layer1.0.bn2.bias: layer1.0.conv2.block.norm.bias
  layer1.0.bn2.running_mean: layer1.0.conv2.block.norm.running_mean
  layer1.0.bn2.running_var: layer1.0.conv2.block.norm.running_var
  layer1.0.conv3.weight: layer1.0.conv3.block.conv.weight
  layer1.0.bn3.weight: layer1.0.conv3.block.norm.weight
  layer1.0.bn3.bias: layer1.0.conv3.block.norm.bias
  layer1.0.bn3.running_mean: layer1.0.conv3.block.norm.running_mean
  layer1.0.bn3.running_var: layer1.0.conv3.block.norm.running_var
  layer1.0.downsample.0.weight: layer1.0.downsample.block.conv.weight
  layer1.0.downsample.1.weight: layer1.0.downsample.block.norm.weight
  layer1.0.downsample.1.bias: layer1.0.downsample.block.norm.bias
  layer1.0.downsample.1.running_mean: layer1.0.downsample.block.norm.running_mean
  layer1.0.downsample.1.running_var: layer1.0.downsample.block.norm.running_var
  layer1.1.conv1.weight: layer1.1.conv1.block.conv.weight
  layer1.1.bn1.weight: layer1.1.conv1.block.norm.weight
  layer1.1.bn1.bias: layer1.1.conv1.block.norm.bias
  layer1.1.bn1.running_mean: layer1.1.conv1.block.norm.running_mean
  layer1.1.bn1.running_var: layer1.1.conv1.block.norm.running_var
  layer1.1.conv2.weight: layer1.1.conv2.block.conv.weight
  layer1.1.bn2.weight: layer1.1.conv2.block.norm.weight
  layer1.1.bn2.bias: layer1.1.conv2.block.norm.bias
  layer1.1.bn2.running_mean: layer1.1.conv2.block.norm.running_mean
  layer1.1.bn2.running_var: layer1.1.conv2.block.norm.running_var
  layer1.1.conv3.weight: layer1.1.conv3.block.conv.weight
  layer1.1.bn3.weight: layer1.1.conv3.block.norm.weight
  layer1.1.bn3.bias: layer1.1.conv3.block.norm.bias
  layer1.1.bn3.running_mean: layer1.1.conv3.block.norm.running_mean
  layer1.1.bn3.running_var: layer1.1.conv3.block.norm.running_var
  layer1.2.conv1.weight: layer1.2.conv1.block.conv.weight
  layer1.2.bn1.weight: layer1.2.conv1.block.norm.weight
  layer1.2.bn1.bias: layer1.2.conv1.block.norm.bias
  layer1.2.bn1.running_mean: layer1.2.conv1.block.norm.running_mean
  layer1.2.bn1.running_var: layer1.2.conv1.block.norm.running_var
  layer1.2.conv2.weight: layer1.2.conv2.block.conv.weight
  layer1.2.bn2.weight: layer1.2.conv2.block.norm.weight
  layer1.2.bn2.bias: layer1.2.conv2.block.norm.bias
  layer1.2.bn2.running_mean: layer1.2.conv2.block.norm.running_mean
  layer1.2.bn2.running_var: layer1.2.conv2.block.norm.running_var
  layer1.2.conv3.weight: layer1.2.conv3.block.conv.weight
  layer1.2.bn3.weight: layer1.2.conv3.block.norm.weight
  layer1.2.bn3.bias: layer1.2.conv3.block.norm.bias
  layer1.2.bn3.running_mean: layer1.2.conv3.block.norm.running_mean
  layer1.2.bn3.running_var: layer1.2.conv3.block.norm.running_var
  layer2.0.conv1.weight: layer2.0.conv1.block.conv.weight
  layer2.0.bn1.weight: layer2.0.conv1.block.norm.weight
  layer2.0.bn1.bias: layer2.0.conv1.block.norm.bias
  layer2.0.bn1.running_mean: layer2.0.conv1.block.norm.running_mean
  layer2.0.bn1.running_var: layer2.0.conv1.block.norm.running_var
  layer2.0.conv2.weight: layer2.0.conv2.block.conv.weight
  layer2.0.bn2.weight: layer2.0.conv2.block.norm.weight
  layer2.0.bn2.bias: layer2.0.conv2.block.norm.bias
  layer2.0.bn2.running_mean: layer2.0.conv2.block.norm.running_mean
  layer2.0.bn2.running_var: layer2.0.conv2.block.norm.running_var
  layer2.0.conv3.weight: layer2.0.conv3.block.conv.weight
  layer2.0.bn3.weight: layer2.0.conv3.block.norm.weight
  layer2.0.bn3.bias: layer2.0.conv3.block.norm.bias
  layer2.0.bn3.running_mean: layer2.0.conv3.block.norm.running_mean
  layer2.0.bn3.running_var: layer2.0.conv3.block.norm.running_var
  layer2.0.downsample.0.weight: layer2.0.downsample.block.conv.weight
  layer2.0.downsample.1.weight: layer2.0.downsample.block.norm.weight
  layer2.0.downsample.1.bias: layer2.0.downsample.block.norm.bias
  layer2.0.downsample.1.running_mean: layer2.0.downsample.block.norm.running_mean
  layer2.0.downsample.1.running_var: layer2.0.downsample.block.norm.running_var
  layer2.1.conv1.weight: layer2.1.conv1.block.conv.weight
  layer2.1.bn1.weight: layer2.1.conv1.block.norm.weight
  layer2.1.bn1.bias: layer2.1.conv1.block.norm.bias
  layer2.1.bn1.running_mean: layer2.1.conv1.block.norm.running_mean
  layer2.1.bn1.running_var: layer2.1.conv1.block.norm.running_var
  layer2.1.conv2.weight: layer2.1.conv2.block.conv.weight
  layer2.1.bn2.weight: layer2.1.conv2.block.norm.weight
  layer2.1.bn2.bias: layer2.1.conv2.block.norm.bias
  layer2.1.bn2.running_mean: layer2.1.conv2.block.norm.running_mean
  layer2.1.bn2.running_var: layer2.1.conv2.block.norm.running_var
  layer2.1.conv3.weight: layer2.1.conv3.block.conv.weight
  layer2.1.bn3.weight: layer2.1.conv3.block.norm.weight
  layer2.1.bn3.bias: layer2.1.conv3.block.norm.bias
  layer2.1.bn3.running_mean: layer2.1.conv3.block.norm.running_mean
  layer2.1.bn3.running_var: layer2.1.conv3.block.norm.running_var
  layer2.2.conv1.weight: layer2.2.conv1.block.conv.weight
  layer2.2.bn1.weight: layer2.2.conv1.block.norm.weight
  layer2.2.bn1.bias: layer2.2.conv1.block.norm.bias
  layer2.2.bn1.running_mean: layer2.2.conv1.block.norm.running_mean
  layer2.2.bn1.running_var: layer2.2.conv1.block.norm.running_var
  layer2.2.conv2.weight: layer2.2.conv2.block.conv.weight
  layer2.2.bn2.weight: layer2.2.conv2.block.norm.weight
  layer2.2.bn2.bias: layer2.2.conv2.block.norm.bias
  layer2.2.bn2.running_mean: layer2.2.conv2.block.norm.running_mean
  layer2.2.bn2.running_var: layer2.2.conv2.block.norm.running_var
  layer2.2.conv3.weight: layer2.2.conv3.block.conv.weight
  layer2.2.bn3.weight: layer2.2.conv3.block.norm.weight
  layer2.2.bn3.bias: layer2.2.conv3.block.norm.bias
  layer2.2.bn3.running_mean: layer2.2.conv3.block.norm.running_mean
  layer2.2.bn3.running_var: layer2.2.conv3.block.norm.running_var
  layer2.3.conv1.weight: layer2.3.conv1.block.conv.weight
  layer2.3.bn1.weight: layer2.3.conv1.block.norm.weight
  layer2.3.bn1.bias: layer2.3.conv1.block.norm.bias
  layer2.3.bn1.running_mean: layer2.3.conv1.block.norm.running_mean
  layer2.3.bn1.running_var: layer2.3.conv1.block.norm.running_var
  layer2.3.conv2.weight: layer2.3.conv2.block.conv.weight
  layer2.3.bn2.weight: layer2.3.conv2.block.norm.weight
  layer2.3.bn2.bias: layer2.3.conv2.block.norm.bias
  layer2.3.bn2.running_mean: layer2.3.conv2.block.norm.running_mean
  layer2.3.bn2.running_var: layer2.3.conv2.block.norm.running_var
  layer2.3.conv3.weight: layer2.3.conv3.block.conv.weight
  layer2.3.bn3.weight: layer2.3.conv3.block.norm.weight
  layer2.3.bn3.bias: layer2.3.conv3.block.norm.bias
  layer2.3.bn3.running_mean: layer2.3.conv3.block.norm.running_mean
  layer2.3.bn3.running_var: layer2.3.conv3.block.norm.running_var
  layer3.0.conv1.weight: layer3.0.conv1.block.conv.weight
  layer3.0.bn1.weight: layer3.0.conv1.block.norm.weight
  layer3.0.bn1.bias: layer3.0.conv1.block.norm.bias
  layer3.0.bn1.running_mean: layer3.0.conv1.block.norm.running_mean
  layer3.0.bn1.running_var: layer3.0.conv1.block.norm.running_var
  layer3.0.conv2.weight: layer3.0.conv2.block.conv.weight
  layer3.0.bn2.weight: layer3.0.conv2.block.norm.weight
  layer3.0.bn2.bias: layer3.0.conv2.block.norm.bias
  layer3.0.bn2.running_mean: layer3.0.conv2.block.norm.running_mean
  layer3.0.bn2.running_var: layer3.0.conv2.block.norm.running_var
  layer3.0.conv3.weight: layer3.0.conv3.block.conv.weight
  layer3.0.bn3.weight: layer3.0.conv3.block.norm.weight
  layer3.0.bn3.bias: layer3.0.conv3.block.norm.bias
  layer3.0.bn3.running_mean: layer3.0.conv3.block.norm.running_mean
  layer3.0.bn3.running_var: layer3.0.conv3.block.norm.running_var
  layer3.0.downsample.0.weight: layer3.0.downsample.block.conv.weight
  layer3.0.downsample.1.weight: layer3.0.downsample.block.norm.weight
  layer3.0.downsample.1.bias: layer3.0.downsample.block.norm.bias
  layer3.0.downsample.1.running_mean: layer3.0.downsample.block.norm.running_mean
  layer3.0.downsample.1.running_var: layer3.0.downsample.block.norm.running_var
  layer3.1.conv1.weight: layer3.1.conv1.block.conv.weight
  layer3.1.bn1.weight: layer3.1.conv1.block.norm.weight
  layer3.1.bn1.bias: layer3.1.conv1.block.norm.bias
  layer3.1.bn1.running_mean: layer3.1.conv1.block.norm.running_mean
  layer3.1.bn1.running_var: layer3.1.conv1.block.norm.running_var
  layer3.1.conv2.weight: layer3.1.conv2.block.conv.weight
  layer3.1.bn2.weight: layer3.1.conv2.block.norm.weight
  layer3.1.bn2.bias: layer3.1.conv2.block.norm.bias
  layer3.1.bn2.running_mean: layer3.1.conv2.block.norm.running_mean
  layer3.1.bn2.running_var: layer3.1.conv2.block.norm.running_var
  layer3.1.conv3.weight: layer3.1.conv3.block.conv.weight
  layer3.1.bn3.weight: layer3.1.conv3.block.norm.weight
  layer3.1.bn3.bias: layer3.1.conv3.block.norm.bias
  layer3.1.bn3.running_mean: layer3.1.conv3.block.norm.running_mean
  layer3.1.bn3.running_var: layer3.1.conv3.block.norm.running_var
  layer3.2.conv1.weight: layer3.2.conv1.block.conv.weight
  layer3.2.bn1.weight: layer3.2.conv1.block.norm.weight
  layer3.2.bn1.bias: layer3.2.conv1.block.norm.bias
  layer3.2.bn1.running_mean: layer3.2.conv1.block.norm.running_mean
  layer3.2.bn1.running_var: layer3.2.conv1.block.norm.running_var
  layer3.2.conv2.weight: layer3.2.conv2.block.conv.weight
  layer3.2.bn2.weight: layer3.2.conv2.block.norm.weight
  layer3.2.bn2.bias: layer3.2.conv2.block.norm.bias
  layer3.2.bn2.running_mean: layer3.2.conv2.block.norm.running_mean
  layer3.2.bn2.running_var: layer3.2.conv2.block.norm.running_var
  layer3.2.conv3.weight: layer3.2.conv3.block.conv.weight
  layer3.2.bn3.weight: layer3.2.conv3.block.norm.weight
  layer3.2.bn3.bias: layer3.2.conv3.block.norm.bias
  layer3.2.bn3.running_mean: layer3.2.conv3.block.norm.running_mean
  layer3.2.bn3.running_var: layer3.2.conv3.block.norm.running_var
  layer3.3.conv1.weight: layer3.3.conv1.block.conv.weight
  layer3.3.bn1.weight: layer3.3.conv1.block.norm.weight
  layer3.3.bn1.bias: layer3.3.conv1.block.norm.bias
  layer3.3.bn1.running_mean: layer3.3.conv1.block.norm.running_mean
  layer3.3.bn1.running_var: layer3.3.conv1.block.norm.running_var
  layer3.3.conv2.weight: layer3.3.conv2.block.conv.weight
  layer3.3.bn2.weight: layer3.3.conv2.block.norm.weight
  layer3.3.bn2.bias: layer3.3.conv2.block.norm.bias
  layer3.3.bn2.running_mean: layer3.3.conv2.block.norm.running_mean
  layer3.3.bn2.running_var: layer3.3.conv2.block.norm.running_var
  layer3.3.conv3.weight: layer3.3.conv3.block.conv.weight
  layer3.3.bn3.weight: layer3.3.conv3.block.norm.weight
  layer3.3.bn3.bias: layer3.3.conv3.block.norm.bias
  layer3.3.bn3.running_mean: layer3.3.conv3.block.norm.running_mean
  layer3.3.bn3.running_var: layer3.3.conv3.block.norm.running_var
  layer3.4.conv1.weight: layer3.4.conv1.block.conv.weight
  layer3.4.bn1.weight: layer3.4.conv1.block.norm.weight
  layer3.4.bn1.bias: layer3.4.conv1.block.norm.bias
  layer3.4.bn1.running_mean: layer3.4.conv1.block.norm.running_mean
  layer3.4.bn1.running_var: layer3.4.conv1.block.norm.running_var
  layer3.4.conv2.weight: layer3.4.conv2.block.conv.weight
  layer3.4.bn2.weight: layer3.4.conv2.block.norm.weight
  layer3.4.bn2.bias: layer3.4.conv2.block.norm.bias
  layer3.4.bn2.running_mean: layer3.4.conv2.block.norm.running_mean
  layer3.4.bn2.running_var: layer3.4.conv2.block.norm.running_var
  layer3.4.conv3.weight: layer3.4.conv3.block.conv.weight
  layer3.4.bn3.weight: layer3.4.conv3.block.norm.weight
  layer3.4.bn3.bias: layer3.4.conv3.block.norm.bias
  layer3.4.bn3.running_mean: layer3.4.conv3.block.norm.running_mean
  layer3.4.bn3.running_var: layer3.4.conv3.block.norm.running_var
  layer3.5.conv1.weight: layer3.5.conv1.block.conv.weight
  layer3.5.bn1.weight: layer3.5.conv1.block.norm.weight
  layer3.5.bn1.bias: layer3.5.conv1.block.norm.bias
  layer3.5.bn1.running_mean: layer3.5.conv1.block.norm.running_mean
  layer3.5.bn1.running_var: layer3.5.conv1.block.norm.running_var
  layer3.5.conv2.weight: layer3.5.conv2.block.conv.weight
  layer3.5.bn2.weight: layer3.5.conv2.block.norm.weight
  layer3.5.bn2.bias: layer3.5.conv2.block.norm.bias
  layer3.5.bn2.running_mean: layer3.5.conv2.block.norm.running_mean
  layer3.5.bn2.running_var: layer3.5.conv2.block.norm.running_var
  layer3.5.conv3.weight: layer3.5.conv3.block.conv.weight
  layer3.5.bn3.weight: layer3.5.conv3.block.norm.weight
  layer3.5.bn3.bias: layer3.5.conv3.block.norm.bias
  layer3.5.bn3.running_mean: layer3.5.conv3.block.norm.running_mean
  layer3.5.bn3.running_var: layer3.5.conv3.block.norm.running_var
  layer4.0.conv1.weight: layer4.0.conv1.block.conv.weight
  layer4.0.bn1.weight: layer4.0.conv1.block.norm.weight
  layer4.0.bn1.bias: layer4.0.conv1.block.norm.bias
  layer4.0.bn1.running_mean: layer4.0.conv1.block.norm.running_mean
  layer4.0.bn1.running_var: layer4.0.conv1.block.norm.running_var
  layer4.0.conv2.weight: layer4.0.conv2.block.conv.weight
  layer4.0.bn2.weight: layer4.0.conv2.block.norm.weight
  layer4.0.bn2.bias: layer4.0.conv2.block.norm.bias
  layer4.0.bn2.running_mean: layer4.0.conv2.block.norm.running_mean
  layer4.0.bn2.running_var: layer4.0.conv2.block.norm.running_var
  layer4.0.conv3.weight: layer4.0.conv3.block.conv.weight
  layer4.0.bn3.weight: layer4.0.conv3.block.norm.weight
  layer4.0.bn3.bias: layer4.0.conv3.block.norm.bias
  layer4.0.bn3.running_mean: layer4.0.conv3.block.norm.running_mean
  layer4.0.bn3.running_var: layer4.0.conv3.block.norm.running_var
  layer4.0.downsample.0.weight: layer4.0.downsample.block.conv.weight
  layer4.0.downsample.1.weight: layer4.0.downsample.block.norm.weight
  layer4.0.downsample.1.bias: layer4.0.downsample.block.norm.bias
  layer4.0.downsample.1.running_mean: layer4.0.downsample.block.norm.running_mean
  layer4.0.downsample.1.running_var: layer4.0.downsample.block.norm.running_var
  layer4.1.conv1.weight: layer4.1.conv1.block.conv.weight
  layer4.1.bn1.weight: layer4.1.conv1.block.norm.weight
  layer4.1.bn1.bias: layer4.1.conv1.block.norm.bias
  layer4.1.bn1.running_mean: layer4.1.conv1.block.norm.running_mean
  layer4.1.bn1.running_var: layer4.1.conv1.block.norm.running_var
  layer4.1.conv2.weight: layer4.1.conv2.block.conv.weight
  layer4.1.bn2.weight: layer4.1.conv2.block.norm.weight
  layer4.1.bn2.bias: layer4.1.conv2.block.norm.bias
  layer4.1.bn2.running_mean: layer4.1.conv2.block.norm.running_mean
  layer4.1.bn2.running_var: layer4.1.conv2.block.norm.running_var
  layer4.1.conv3.weight: layer4.1.conv3.block.conv.weight
  layer4.1.bn3.weight: layer4.1.conv3.block.norm.weight
  layer4.1.bn3.bias: layer4.1.conv3.block.norm.bias
  layer4.1.bn3.running_mean: layer4.1.conv3.block.norm.running_mean
  layer4.1.bn3.running_var: layer4.1.conv3.block.norm.running_var
  layer4.2.conv1.weight: layer4.2.conv1.block.conv.weight
  layer4.2.bn1.weight: layer4.2.conv1.block.norm.weight
  layer4.2.bn1.bias: layer4.2.conv1.block.norm.bias
  layer4.2.bn1.running_mean: layer4.2.conv1.block.norm.running_mean
  layer4.2.bn1.running_var: layer4.2.conv1.block.norm.running_var
  layer4.2.conv2.weight: layer4.2.conv2.block.conv.weight
  layer4.2.bn2.weight: layer4.2.conv2.block.norm.weight
  layer4.2.bn2.bias: layer4.2.conv2.block.norm.bias
  layer4.2.bn2.running_mean: layer4.2.conv2.block.norm.running_mean
  layer4.2.bn2.running_var: layer4.2.conv2.block.norm.running_var
  layer4.2.conv3.weight: layer4.2.conv3.block.conv.weight
  layer4.2.bn3.weight: layer4.2.conv3.block.norm.weight
  layer4.2.bn3.bias: layer4.2.conv3.block.norm.bias
  layer4.2.bn3.running_mean: layer4.2.conv3.block.norm.running_mean
  layer4.2.bn3.running_var: layer4.2.conv3.block.norm.running_var
  fc.weight: ~
  fc.bias: ~